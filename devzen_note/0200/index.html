<!DOCTYPE html>
<html lang="en-us">
    <head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
		<title>
				Notes for episode-0200 &middot; DevZen Podcast Notes
		</title>
	
		
  		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
	
		
		<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
	
		
		<link href="" rel="alternate" type="application/rss+xml" title="DevZen Podcast Notes" />
	</head>
	
    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/">
					<h2 class="nav-title">DevZen Podcast Notes</h2>
				</a>
				<ul>
    <li><a href="/about">About</a></li>
    <li><a href="/">Posts</a></li>
</ul>
			</div>
		</nav>

        

<main>
	<div class="post">
        <div class="post-title">Notes for episode-0200</div>
        <div class="post-line"></div>

		

		

<h1 id="openai-five-versus-dota">OpenAI Five versus Dota</h1>

<p><a href="https://blog.openai.com/openai-five/">https://blog.openai.com/openai-five/</a></p>

<ul>
<li>Отличное оформление блога: интерактивные картинки, поясняющие текущее состояние модели, цели, …</li>
<li>OpenAI - это некоммерческая исследовательская организация</li>
<li>OpenAI Five - команда из 5 нейронных сетей</li>
<li>Начала побеждать новичков в Dota2.</li>
<li>Сейчас играют с ограничениями, но цель - победить на мировом соревновании “The International”</li>
<li>Dota2 - одна из самых сложных электронных игр в мире</li>
<li>OpenAI Five играет 180 лет сама против себя каждый день</li>
<li>Использует Reinforcement Learning, и работает на 256GPUs, и 128000 CPU cores</li>
<li>Использует LSTM для каждого героя, без данных от человека, алгоритм вырабатывает сам узнаваемые стратегии</li>
<li>=&gt; Reinforcement learning может создавать долгосрочные цели</li>
<li>28 Июля - будет очередной матч с топовой командой, чтобы проверить уровень</li>
<li>Одна из целей OpenAI  - превзойти человека в сложных видеоиграх (StarCraft/Dota2).</li>
<li>По сравнению с предыдущими целями (Шахматы, Го), сложные видеоигры - уже повторяют хаос и продолжительную структуру реального мира. Поэтому есть надежда, что достижения в видеоиграх помогут в других областях (т.е. получится более генеральное решение)</li>
<li>ИИ, играющий в Dota2 должен управлять:

<ul>
<li>Долгосрочным планированием: 30rps * 45 min (average) = 80k ticks per game. Отдельный приказ - мало влияет на игру в целом, есть отдельные стратегические приказы, которые сильно воздействуют на игру (town portal). Стратегии могут продолжаться всю игру. Шахматы в среднем 40 ходов, Go - 150</li>
<li>Частично-доступным обзором. Видна только часть информации, нужно делать выводы и предполагать, что сейчас делает противник. Chess/Go - видно все</li>
<li>Высоко-размерная, длительная область действий игрока: десятки возможных действий, разные цели для действий (башня, персонаж, координата). Они описали область действий - 170к возможных действий (не все активны все время), в среднем ~1k валидных действий каждый тик. В шахматах - 35, в Go 250</li>
<li>Огромная область вариантов. Игра описывается 10 игроками, десятки зданий, NPC юнитов, деревьев, руны, … Их модель игры описывает состояние с помощью 20k чисел (в основном, с плавающей точкой)</li>
</ul></li>
<li>Боты учатся только на собственном опыте,</li>
<li>ожидали, что потребуются ухищрения, чтобы делать долгосрочное планирование (hierarchical reinforcement learning), в целом оказалось, что даже текущие алгоритмы дают хорошее планирование (жертвование краткосрочными целями ради достижения каких-то более стратегических целей)</li>
<li>Выводы, интересные наблюдения про отличия от человека и т.д.</li>
</ul>

<h1 id="с-это-не-низкоуровневый-язык">С - это НЕ низкоуровневый язык</h1>

<p><a href="https://queue.acm.org/detail.cfm?id=3212479">https://queue.acm.org/detail.cfm?id=3212479</a></p>

<ul>
<li>Meltdown, Spectre: спекулятивное выполнение + просмотр результатов через side channel.</li>
<li>Фичи, необходимые для этого, были добавлены в язык, чтобы люди продолжали думать, что они программируют на низкоуровневом языке</li>
<li>Low-Level: by “computer science pioneer Alan Perlis” &rdquo;A programming language is low level when its programs require attention to the irrelevant.&rdquo;</li>
<li>C - был низкоуровневым для PDP-11, где:

<ul>
<li>Программа исполнялась последовательно</li>
<li>память была плоским пространством (не иерархическая)</li>
<li>и т.д.</li>
</ul></li>
<li>Главная причина уязвимостей - что архитекторы процессора старались построить быстрый процессор, который был подобен PDP-11. Это позволяло программистам верить, что C - близок нижестоящей платформе.</li>
<li>Си предоставляет в основном последовательную абстрактную машину, создание нового потока - дорогое удовольствие.</li>
<li>Поэтому производительный код полагается на ILP (instruction-level parallelism): соседние операции проверяются, и независимые выполняются впараллель.</li>
<li>Чтобы написать по настоящему “последовательный” код - нужно сильно захотеть, и это добавит сложности.</li>
<li>Квест по достижению высокого ILP - привело непосредственно к Spectre и Meltdown.</li>
<li>Современные Intel-процессоры имеют вплоть до 180 инструкций “в полете” в любой момент времени. (сравните с последовательной машиной, где следующая инструкция выполняется только после окончания предыдущей)</li>
<li>Эвристика: ветвление на каждые 7 инструкций, чтобы наполнить работой пайплайн, вы должны предсказать следующие <sup>180</sup>&frasl;<sub>7</sub> ~ 25 переходов. Это опять добавляет сложности</li>
<li>Неправильное предположение о ветвлении - работу выкинуть, что не очень хорошо для потребления памяти</li>
<li>И не очень хорошо с точки зрения уязвимостей :)</li>
<li>Переименователь регистров - потребляет кучу энергии, добавляет сложности, нужно только для реорганизации выполнения, для создания параллелизма из последовательного выполнения (нет на GPU, где все выполняется впараллель)</li>
<li>Плоская модель памяти - неправда уже на протяжении 20 лет (3 уровня кэша для уменьшения latency)</li>
<li>Кэш спрятан от программиста, не виден в C. Для эффективной программы - нужно знать, как кэш работает, и как в него поместиться (архитектурно-зависимо)</li>
<li>ОПТИМИЗАЦИЯ С</li>
<li>Приписывают скорость low-level языкам</li>
<li>Несложный компилятор должен уметь транслировать программу в быстрый код</li>
<li>Вообще, любой язык можно сделать быстрым, достаточно иметь очень хороший компилятор!</li>
<li>Но для Си не работает эта аксиома: простой компилятор не сделает быстрый код.</li>
<li>Только сложные оптимизации, только хардкор!</li>
<li>CLang - 2M LOC</li>
<li>Пример: обработка большого массива данных - это цикл с пробеганием по одному элементу.</li>
<li>Чтобы оптимально отработать на современных CPU - компилятор сперва определяет, что итерации независимы (restrict ключевое слово может помочь)</li>
<li>Если доказал - векторизует результат (4x-8x растет производительность на векторных инструкциях)</li>
<li>Потом Оптимизатор борется с гарантиями расположения C-памяти (нельзя менять местами поля структуры, добавлять padding, etc). Это свойство низкоуровневого языка, но не свойство быстрого языка, конфликт интересов налицо :)</li>
<li>сравнение структур по стандарту можно делать с помощью memcpy, поэтому копирование структур делается с копированием padding. В некоторых тестах это занимает значительную часть времени. Опять конфликт интересов</li>
<li>loop unswitching: оптимизация, когда цикл с условием в теле преобразуется в условие + два цикла по обоим путям условия. Это ускоряет (нет сравнения в цикле), но одновременно расходится с понятием “низкоуровневого языка”, когда ты точно знаешь, что происходит в твоей программе. По сути - мы меняем flow control.</li>
<li>В итоге, можно заставить код работать быстро, но надо тысячи человеко лет на построение хорошего компилятора. “близкий к металлу” язык, но компилятор генерирует код, который имеет совершенно другое поведение, чтобы заставить работать код “быстро”</li>
<li>ПОНИМАНИЕ С</li>
<li>ключевая особенность низкоуровневого языка - программисты легко могут понять, как абстрактная машина языка использует физическую машину.</li>
<li>это было верно для PDP-11, для современности - это совсем не так</li>
<li>пример: опрос 2015 года для си-программистов, писателей компиляторов и членов программного комитета. Вопрос: язык позволяет добавлять padding в структуру, чтобы поля были выровнены. Если вы обнуляете структуру и затем устанавливаете некоторые поля - будут ли padding-биты все еще нулями? 36% - были уверены, что да, 29% - не знали. Это зависит от компилятора и уровня оптимизации.</li>
<li>Это простейший пример, и то большАя часть не знает правильного ответа</li>
<li>Указатели добавляют сложности:

<ul>
<li>Выделили и освободили память, выделили снова, попали на эту же область. Сравнение указателей дает true?</li>
<li>pointer -&gt; cast integer -&gt; cast pointer, сравнение указателей дает true?</li>
<li>Везде - зависит от компилятора, даже если побитное сравнение указателей совпадает</li>
</ul></li>
<li>Это не чистая академичность, это попытка защититься от уязвимостей</li>
<li>Поэтому тяжело ожидать, что все понимают, как на низком уровне работает их программа на си</li>
<li>ПРЕДСТАВИМ НЕ-С ПРОЦЕССОРЫ</li>
<li>Meltdown/Spectre заставили внести изменения, которые СИЛЬНО замедляют выполнение всех программ.</li>
<li>Хватит развивать архитектуру по пути “сделаем код на си быстрым”, и вместо этого понять - какая программная модель должна быть на хорошем быстром процессоре?</li>
<li>Есть много альтернативных архитектур, которые не создавались для “С-кода”.

<ul>
<li>Sun UltraSPARC Tx серия - не требует много кэша, чтобы заполнить все модули процессора работой. можно замораживать потоки, которые ожидают данных, и выполнять другую работу.</li>
<li>ARM SVE (Scalar Vector Extensions) - предоставляют векторные операции, компилятор их должен заполнять. Программист при этом описывает уровень параллелизма. Хорошо подходит функциональный код</li>
<li>Самая сложная часть системы памяти - поддержка когерентности кэша. Все из-за программ, где данные одновременно мутабельные и расшаренные. Вместо этого можно рассмотреть модель, где данные либо мутабельны но для одного потока, либо иммутабельны, но общие. Erlang.</li>
<li>Иммутабельные объекты могут упростить кэш еще больше. Project Maxwell (Sun Labs). Если данные уже мертвы - их не нужно синхронизировать из кэша в память, можно хитрее работать с GC (generational GC), мутабельные данные - только на стэке, упрощается архитектура</li>
</ul></li>
<li>ВЫВОДЫ:</li>
<li>Процессор, оптимизированный только на скорость, не на поддержку Си - будет проще, сможет поддерживать большое количество потоков, сможет использовать векторные вычисления шире и т.д. Проблема - не сможет хорошо работать с Си</li>
<li>Общий миф, что параллельное программирование сложно. Алан Кей смог учить школьников акторной модели. Эрлангисты пишут программы с тысячами потоков. Правильный факт: Параллельное программирование на С-подобной абстракции - это сложно. И то, как машины все больше уходят в параллельность, GPUs, multiCores -&gt; Си плохо ложится на современную архитектуру и будет ложится все хуже</li>
</ul>


		
	</div>

	<div class="pagination">
		<a href="/devzen_note/0199/" class="left arrow">&#8592;</a>
		<a href="/devzen_note/0201/" class="right arrow">&#8594;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			<span>
			&copy; <time datetime="2019-01-20 01:15:59.717488 &#43;0400 &#43;04 m=&#43;0.078006257">2019</time> . Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
		</footer>

    </body>
</html>
